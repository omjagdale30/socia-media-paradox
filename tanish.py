import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.decomposition import PCA
from sklearn.model_selection import cross_val_score
from imblearn.over_sampling import SMOTE
import plotly.express as px
import plotly.graph_objects as go
import joblib

# Title and Introduction
st.title("The Social Media Paradox - Enhanced Analysis")
st.markdown("""
Welcome to the Global Digital Well-being Research Institute (GDWRI) Dashboard.  
Analyze social media usage patterns and their impact on well-being with advanced statistical and machine learning techniques.
""")

# Sidebar for file upload
st.sidebar.header("Data Upload")
health_file = st.sidebar.file_uploader("Upload Sleep Dataset (Sleep Dataset.xlsm)", type=["xlsm"])
social_file = st.sidebar.file_uploader("Upload Social Media Usage (Social Media Usage - Train.xlsm)", type=["xlsm"])

# Function to categorize usage
def categorize_usage(minutes):
    if minutes < 60: return 'Low'
    elif minutes < 120: return 'Moderate'
    else: return 'High'

# Main app logic
if health_file and social_file:
    # Load datasets
    try:
        health_data = pd.read_excel(health_file)
        social_media_data = pd.read_excel(social_file)
    except Exception as e:
        st.error(f"Error loading files: {e}")
        st.stop()

    # =============================================
    # Enhanced Data Quality Checks
    # =============================================
    st.header(" Data Quality Checks")
    
    with st.expander("Data Quality Validation", expanded=True):
        # Duplicate Check
        st.subheader("Duplicate Records Check")
        col1, col2 = st.columns(2)
        with col1:
            health_dups = health_data.duplicated().sum()
            st.metric("Health Data Duplicates", health_dups)
            if health_dups > 0:
                st.warning("Duplicate rows found in health data")
        
        with col2:
            social_dups = social_media_data.duplicated().sum()
            st.metric("Social Media Data Duplicates", social_dups)
            if social_dups > 0:
                st.warning("Duplicate rows found in social media data")
        
        # Null Check
        st.subheader("Missing Values Analysis")
        tab1, tab2 = st.tabs(["Health Data", "Social Media Data"])
        
        with tab1:
            health_nulls = health_data.isnull().sum()
            st.write("Null Values Count:")
            st.write(health_nulls)
            if health_nulls.sum() > 0:
                st.warning("Missing values detected in health data")
        
        with tab2:
            social_nulls = social_media_data.isnull().sum()
            st.write("Null Values Count:")
            st.write(social_nulls)
            if social_nulls.sum() > 0:
                st.warning("Missing values detected in social media data")
        
        # Data Type Verification
        st.subheader("Data Types Validation")
        col1, col2 = st.columns(2)
        with col1:
            st.write("Health Data Types:")
            st.write(health_data.dtypes)
        
        with col2:
            st.write("Social Media Data Types:")
            st.write(social_media_data.dtypes)
        
        # Range Check
        st.subheader("Value Range Validation")
        numeric_cols_health = health_data.select_dtypes(include=np.number).columns
        numeric_cols_social = social_media_data.select_dtypes(include=np.number).columns
        
        st.write("Health Data Ranges:")
        range_df_health = pd.DataFrame({
            'Column': numeric_cols_health,
            'Min': health_data[numeric_cols_health].min(),
            'Max': health_data[numeric_cols_health].max()
        })
        st.dataframe(range_df_health)
        
        st.write("Social Media Data Ranges:")
        range_df_social = pd.DataFrame({
            'Column': numeric_cols_social,
            'Min': social_media_data[numeric_cols_social].min(),
            'Max': social_media_data[numeric_cols_social].max()
        })
        st.dataframe(range_df_social)

    # =============================================
    # Data Processing
    # =============================================
    st.header("âš™ï¸ Data Processing")
    
    with st.expander("Data Cleaning Steps", expanded=False):
        # Handle missing values
        health_data['Sleep Disorder'] = health_data['Sleep Disorder'].fillna('None')
        health_data['BMI Category'] = health_data['BMI Category'].str.replace('Normal Weight', 'Normal')
        
        # Remove duplicates if any found
        if health_dups > 0:
            health_data = health_data.drop_duplicates()
            st.success(f"Removed {health_dups} duplicate rows from health data")
        
        if social_dups > 0:
            social_media_data = social_media_data.drop_duplicates()
            st.success(f"Removed {social_dups} duplicate rows from social media data")
        
        # Clean text data
        social_media_data = social_media_data.dropna()
        social_media_data['Dominant_Emotion'] = social_media_data['Dominant_Emotion'].str.strip()
        
        st.success("Data cleaning completed!")

    # Feature Engineering
    with st.expander("Feature Engineering", expanded=False):
        health_data['Health_Score'] = (
            health_data['Quality of Sleep'] * 0.3 + 
            (10 - health_data['Stress Level']) * 0.2 +
            health_data['Physical Activity Level'] * 0.2 +
            health_data['Daily Steps'] / 10000 * 0.3
        )
        health_data['Sleep_Efficiency'] = health_data['Quality of Sleep'] / health_data['Sleep Duration']
        
        social_media_data['Engagement_Rate'] = (
            social_media_data['Likes_Received_Per_Day'] + 
            social_media_data['Comments_Received_Per_Day'] + 
            social_media_data['Messages_Sent_Per_Day']
        ) / social_media_data['Posts_Per_Day'].replace(0, 1)
        
        st.write("Created new features: Health_Score, Sleep_Efficiency, Engagement_Rate")

    # Find usage column
    possible_time_columns = ['Daily Minutes', 'Daily_Usage', 'Minutes_Per_Day', 'Time_Spent', 
                           'Usage_Minutes', 'Daily_Usage_Time (minutes)']
    usage_column = None
    for col in possible_time_columns:
        if col in social_media_data.columns:
            usage_column = col
            break

    if usage_column is None:
        st.error("No time usage column found. Available columns: " + str(social_media_data.columns.tolist()))
        st.stop()
    else:
        st.info(f"Using column '{usage_column}' for usage categorization")
        social_media_data['Usage_Category'] = social_media_data[usage_column].apply(categorize_usage)

    # Merge datasets
    merged_data = pd.merge(
        health_data, 
        social_media_data, 
        left_on='Person ID', 
        right_on='User_ID', 
        how='inner'
    )
    
    if merged_data.empty:
        st.error("Merge failed - no common records found. Trying alternative merge on Age and Gender...")
        common_columns = ['Age', 'Gender']
        if all(col in health_data.columns and col in social_media_data.columns for col in common_columns):
            merged_data = pd.merge(
                health_data,
                social_media_data,
                on=common_columns,
                how='inner'
            )
            if merged_data.empty:
                st.error("Alternative merge also failed - no common records found")
                st.stop()
        else:
            st.error("Common columns not found for alternative merge")
            st.stop()

    # =============================================
    # Statistical Analysis
    # =============================================
    st.header("ðŸ“Š Statistical Analysis")
    
    with st.expander("Statistical Measures", expanded=False):
        st.subheader("Descriptive Statistics")
        
        health_stats = health_data[numeric_cols_health].agg(['mean', 'std', 'skew', 'var', 'min', 'max']).T
        social_stats = social_media_data[numeric_cols_social].agg(['mean', 'std', 'skew', 'var', 'min', 'max']).T
        
        st.write("Health Data Statistics:")
        st.dataframe(health_stats.style.format("{:.2f}"))
        
        st.write("Social Media Data Statistics:")
        st.dataframe(social_stats.style.format("{:.2f}"))
        
        st.subheader("Skewness Visualization")
        fig = px.bar(health_stats.reset_index(), x='index', y='skew', title="Skewness of Health Data Features")
        st.plotly_chart(fig)
        
        fig = px.bar(social_stats.reset_index(), x='index', y='skew', title="Skewness of Social Media Data Features")
        st.plotly_chart(fig)

    # =============================================
    # Correlation Analysis
    # =============================================
    st.header("ðŸ”— Correlation Analysis")
    
    numeric_cols_merged = merged_data.select_dtypes(include=np.number).columns
    corr_matrix = merged_data[numeric_cols_merged].corr()
    
    fig_corr = px.imshow(
        corr_matrix, 
        text_auto=True, 
        title="Correlation Matrix of Numeric Features",
        color_continuous_scale='RdBu',
        zmin=-1,
        zmax=1
    )
    st.plotly_chart(fig_corr, use_container_width=True)
    
    # =============================================
    # Machine Learning Models
    # =============================================
    st.header(" Machine Learning Models")
    
    # Handle duplicate columns after merge
    age_col = 'Age' if 'Age' in merged_data.columns else 'Age_x'
    gender_col = 'Gender' if 'Gender' in merged_data.columns else 'Gender_x'

    # Platform Prediction Model
    st.subheader("Platform Prediction Model")
    
    with st.expander("Model Configuration", expanded=False):
        X_platform = merged_data[[age_col, gender_col, 'Occupation', 'Health_Score', 'Sleep_Efficiency', 'Engagement_Rate', usage_column]].copy()
        y_platform = merged_data['Platform']

        le_gender = LabelEncoder()
        le_occupation = LabelEncoder()
        le_platform = LabelEncoder()

        X_platform[gender_col] = le_gender.fit_transform(X_platform[gender_col])
        X_platform['Occupation'] = le_occupation.fit_transform(X_platform['Occupation'])
        y_platform = le_platform.fit_transform(y_platform)

        # Handle class imbalance with SMOTE
        smote = SMOTE(random_state=42)
        X_platform_balanced, y_platform_balanced = smote.fit_resample(X_platform, y_platform)

        X_train, X_test, y_train, y_test = train_test_split(
            X_platform_balanced, 
            y_platform_balanced, 
            test_size=0.2, 
            random_state=42
        )

        numeric_features = [age_col, 'Health_Score', 'Sleep_Efficiency', 'Engagement_Rate', usage_column]
        categorical_features = [gender_col, 'Occupation']

        preprocessor = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), numeric_features),
                ('cat', 'passthrough', categorical_features)
            ])

        # Hyperparameter tuning with GridSearchCV
        param_grid = {
            'classifier__n_estimators': [100, 200],
            'classifier__max_depth': [5, 10, 15],
            'classifier__min_samples_split': [2, 5]
        }
        
        platform_model = Pipeline([
            ('preprocessor', preprocessor),
            ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))
        ])

        grid_search = GridSearchCV(platform_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)
        grid_search.fit(X_train, y_train)
        platform_model = grid_search.best_estimator_
        y_pred = platform_model.predict(X_test)
        
        # Store encoders for later use
        joblib.dump(le_gender, 'gender_encoder.joblib')
        joblib.dump(le_occupation, 'occupation_encoder.joblib')
        joblib.dump(le_platform, 'platform_encoder.joblib')

    # Display model results
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Accuracy", f"{accuracy_score(y_test, y_pred):.2%}")
    with col2:
        st.metric("Best Parameters", str(grid_search.best_params_))
    with col3:
        st.metric("Cross-Val Score", f"{cross_val_score(platform_model, X_platform_balanced, y_platform_balanced, cv=5).mean():.2%}")

    # Detailed metrics
    with st.expander("Detailed Classification Report"):
        st.text(classification_report(y_test, y_pred, target_names=le_platform.classes_))
    
    # Confusion Matrix
    st.subheader("Confusion Matrix")
    cm_platform = confusion_matrix(y_test, y_pred)
    fig_cm_platform = px.imshow(
        cm_platform,
        text_auto=True,
        labels=dict(x="Predicted", y="Actual"),
        x=le_platform.classes_,
        y=le_platform.classes_,
        color_continuous_scale='Blues'
    )
    st.plotly_chart(fig_cm_platform, use_container_width=True)

    # Feature Importance
    st.subheader("Feature Importance")
    feature_importance = platform_model.named_steps['classifier'].feature_importances_
    feature_names = numeric_features + categorical_features
    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance}).sort_values('Importance', ascending=False)
    
    fig_importance = px.bar(
        importance_df,
        x='Importance',
        y='Feature',
        orientation='h',
        color='Importance',
        color_continuous_scale='Blues'
    )
    st.plotly_chart(fig_importance, use_container_width=True)

    # Bias Analysis
    st.subheader("Bias Analysis by Gender")
    gender_groups = merged_data[gender_col].unique()
    bias_results = []
    
    for group in gender_groups:
        group_mask = X_test[gender_col] == le_gender.transform([group])[0]
        if sum(group_mask) > 0:  # Only calculate if there are samples
            acc = accuracy_score(y_test[group_mask], y_pred[group_mask])
            bias_results.append({
                'Gender': group,
                'Sample Size': sum(group_mask),
                'Accuracy': acc
            })
    
    bias_df = pd.DataFrame(bias_results)
    if not bias_df.empty:
        st.dataframe(bias_df)
        fig_bias = px.bar(bias_df, x='Gender', y='Accuracy', title="Model Accuracy by Gender Group")
        st.plotly_chart(fig_bias)
    else:
        st.warning("Insufficient data for bias analysis by gender")

    # Health Impact Prediction Model
    st.subheader("Health Impact Prediction Model")
    
    with st.expander("Model Configuration", expanded=False):
        X_health = merged_data[[age_col, gender_col, 'Platform', usage_column, 'Usage_Category', 'Engagement_Rate']].copy()
        y_health = (merged_data['Health_Score'] > merged_data['Health_Score'].median()).astype(int)

        X_health[gender_col] = le_gender.transform(X_health[gender_col])
        X_health['Platform'] = le_platform.transform(X_health['Platform'])
        le_usage = LabelEncoder()
        X_health['Usage_Category'] = le_usage.fit_transform(X_health['Usage_Category'])

        X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(
            X_health, 
            y_health, 
            test_size=0.2, 
            random_state=42
        )

        numeric_features_h = [age_col, usage_column, 'Engagement_Rate']
        categorical_features_h = [gender_col, 'Platform', 'Usage_Category']

        preprocessor_h = ColumnTransformer(
            transformers=[
                ('num', Pipeline([
                    ('scaler', StandardScaler()), 
                    ('pca', PCA(n_components=2))
                ]), numeric_features_h),
                ('cat', 'passthrough', categorical_features_h)
            ])

        health_model = Pipeline([
            ('preprocessor', preprocessor_h),
            ('classifier', GradientBoostingClassifier(n_estimators=50, max_depth=5, random_state=42))
        ])

        health_model.fit(X_train_h, y_train_h)
        y_pred_h = health_model.predict(X_test_h)
        
        # Store usage encoder
        joblib.dump(le_usage, 'usage_encoder.joblib')

    # Display health model results
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Accuracy", f"{accuracy_score(y_test_h, y_pred_h):.2%}")
    with col2:
        st.metric("Cross-Val Score", f"{cross_val_score(health_model, X_health, y_health, cv=5).mean():.2%}")

    # Confusion Matrix
    st.subheader("Confusion Matrix")
    cm_health = confusion_matrix(y_test_h, y_pred_h)
    fig_cm_health = px.imshow(
        cm_health,
        text_auto=True,
        labels=dict(x="Predicted", y="Actual"),
        x=['Below Median', 'Above Median'],
        y=['Below Median', 'Above Median'],
        color_continuous_scale='Greens'
    )
    st.plotly_chart(fig_cm_health, use_container_width=True)

    # =============================================
    # Visualization and Insights
    # =============================================
    st.header("ðŸ“ˆ Visualizations & Insights")
    
    tab1, tab2, tab3, tab4 = st.tabs(["Platform Usage", "Health Impact", "Predictions", "Summary"])

    with tab1:
        st.header("Platform Usage by Age Group")
        fig1 = px.box(merged_data, x='Platform', y=age_col, color='Platform', 
                     title="Social Media Platform Usage Across Age Groups")
        st.plotly_chart(fig1, use_container_width=True)

        st.subheader("Platform Popularity by Age Group")
        age_bins = [0, 18, 25, 35, 50, 100]
        age_labels = ['<18', '18-25', '25-35', '35-50', '50+']
        merged_data['Age_Group'] = pd.cut(merged_data[age_col], bins=age_bins, labels=age_labels)
        fig2 = px.histogram(merged_data, x='Platform', color='Age_Group', barmode='group',
                           title="Platform Popularity by Age Group")
        st.plotly_chart(fig2, use_container_width=True)

    with tab2:
        st.header("Health Impact Analysis")
        st.subheader("Correlation with Usage")
        metric = st.selectbox("Select Health Metric", ['Stress Level', 'Quality of Sleep', 'Physical Activity Level'])
        fig3 = px.scatter(merged_data, x=usage_column, y=metric, color='Platform', 
                         title=f"{metric} vs. Social Media Usage Time", trendline="ols")
        st.plotly_chart(fig3, use_container_width=True)

        st.subheader("Sleep Disorders by Usage Category")
        fig4 = px.bar(merged_data.groupby(['Usage_Category', 'Sleep Disorder']).size().reset_index(name='Count'),
                     x='Usage_Category', y='Count', color='Sleep Disorder', 
                     title="Sleep Disorders by Social Media Usage Category", barmode='group')
        st.plotly_chart(fig4, use_container_width=True)

    with tab3:
        st.header("Predictions")
        
        st.subheader("Predict Social Media Platform")
        age = st.number_input("Age", min_value=0, max_value=100, value=25, key="platform_age")
        gender = st.selectbox("Gender", merged_data[gender_col].unique(), key="platform_gender")
        occupation = st.selectbox("Occupation", merged_data['Occupation'].unique(), key="platform_occupation")
        health_score = st.number_input("Health Score (1-10)", min_value=1.0, max_value=10.0, value=7.0, key="platform_health")
        sleep_efficiency = st.number_input("Sleep Efficiency", min_value=0.0, max_value=2.0, value=1.0, key="platform_sleep")
        engagement = st.number_input("Engagement Rate", min_value=0.0, value=1.0, key="platform_engagement")
        usage = st.number_input("Daily Usage Time (minutes)", min_value=0, value=120, key="platform_usage")

        if st.button("Predict Platform", type="primary"):
            input_data = pd.DataFrame({
                age_col: [age],
                gender_col: [gender],
                'Occupation': [occupation],
                'Health_Score': [health_score],
                'Sleep_Efficiency': [sleep_efficiency],
                'Engagement_Rate': [engagement],
                usage_column: [usage]
            })
            input_data[gender_col] = le_gender.transform(input_data[gender_col])
            input_data['Occupation'] = le_occupation.transform(input_data['Occupation'])
            prediction = platform_model.predict(input_data)
            platform = le_platform.inverse_transform(prediction)[0]
            st.success(f"Predicted Platform: **{platform}**")
            
            # Show probabilities
            proba = platform_model.predict_proba(input_data)[0]
            proba_df = pd.DataFrame({
                'Platform': le_platform.classes_,
                'Probability': proba
            }).sort_values('Probability', ascending=False)
            
            fig = px.bar(
                proba_df,
                x='Platform',
                y='Probability',
                color='Probability',
                color_continuous_scale='Blues',
                title="Platform Prediction Probabilities"
            )
            st.plotly_chart(fig, use_container_width=True)

        st.subheader("Predict Health Impact")
        usage = st.number_input("Daily Usage Time (minutes)", min_value=0, value=120, key="health_usage")
        platform = st.selectbox("Platform", merged_data['Platform'].unique(), key="health_platform")
        engagement = st.number_input("Engagement Rate", min_value=0.0, value=1.0, key="health_engagement")

        if st.button("Predict Health Impact", type="primary"):
            usage_cat = categorize_usage(usage)
            input_data = pd.DataFrame({
                age_col: [30],
                gender_col: ['Male'],
                'Platform': [platform],
                usage_column: [usage],
                'Usage_Category': [usage_cat],
                'Engagement_Rate': [engagement]
            })
            input_data[gender_col] = le_gender.transform(input_data[gender_col])
            input_data['Platform'] = le_platform.transform(input_data['Platform'])
            input_data['Usage_Category'] = le_usage.transform(input_data['Usage_Category'])
            health_pred = health_model.predict(input_data)[0]
            health_status = "Above Median" if health_pred == 1 else "Below Median"
            st.success(f"Predicted Health Status: **{health_status}**")
            st.write(f"Based on: {usage} minutes/day on {platform} ({usage_cat} usage), Engagement Rate {engagement}")

    with tab4:
        st.header("Summary and Insights")
        st.markdown("""
        ### Observations from the Enhanced Analysis:
        - **Data Quality**: Comprehensive checks revealed {} duplicate records and {} missing values.
        - **Model Performance**: Platform prediction achieved {:.1f}% accuracy with balanced performance across groups.
        - **Platform Usage**: Younger users favor Instagram/YouTube; older users prefer Facebook/LinkedIn.
        - **Health Impact**: Excessive usage (>120 mins) correlates with higher stress levels (r={:.2f}) and lower sleep quality (r={:.2f}).
        - **Key Drivers**: 'Engagement_Rate' (importance={:.2f}) and 'Health_Score' (importance={:.2f}) were top predictors.

        ### Recommendations:
        - **Data Collection**: Address gaps in {} representation to reduce bias.
        - **Usage Guidelines**: Recommend limiting social media to <120 mins/day for better health outcomes.
        - **Feature Monitoring**: Track engagement quality metrics for early intervention.

        ### Future Work:
        - Longitudinal study on usage patterns and health impacts
        - Platform-specific intervention strategies
        """.format(
            health_dups + social_dups,
            health_nulls.sum() + social_nulls.sum(),
            accuracy_score(y_test, y_pred)*100,
            corr_matrix.loc[usage_column, 'Stress Level'],
            corr_matrix.loc[usage_column, 'Quality of Sleep'],
            importance_df.loc[importance_df['Feature'] == 'Engagement_Rate', 'Importance'].values[0],
            importance_df.loc[importance_df['Feature'] == 'Health_Score', 'Importance'].values[0],
            ", ".join([g for g in gender_groups if bias_df[bias_df['Gender'] == g]['Sample Size'].values[0] < 30]) if not bias_df.empty else "certain demographic"
        ))

else:
    st.warning("Please upload both the Sleep Dataset and Social Media Usage files to proceed.")